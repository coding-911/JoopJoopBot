x-airflow-common: &airflow-common
  build: 
    context: .
    dockerfile: services/airflow/Dockerfile
    args:
      PYTHON_VERSION: "3.11"
  user: "${AIRFLOW_UID}:${AIRFLOW_GID}"
  environment: &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: ${AIRFLOW__CORE__EXECUTOR}
    AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW__CORE__LOAD_EXAMPLES}
    AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${AIRFLOW_POSTGRES_USER}:${AIRFLOW_POSTGRES_PASSWORD}@${POSTGRES_HOST}:5432/${AIRFLOW_POSTGRES_DB}
    PYTHONPATH: /packages/joopjoop-core/src
    AIRFLOW_ALERT_EMAIL: ${AIRFLOW_ALERT_EMAIL}
    AIRFLOW_TASK_RETRIES: ${AIRFLOW_TASK_RETRIES}
    AIRFLOW_RETRY_DELAY_MINUTES: ${AIRFLOW_RETRY_DELAY_MINUTES}
    AIRFLOW_UID: ${AIRFLOW_UID}
    DART_API_KEY: ${DART_API_KEY}
    VECTOR_DB_PATH: ${AIRFLOW_VECTOR_DB_PATH}
    POSTGRES_HOST: ${POSTGRES_HOST}
    POSTGRES_PORT: ${POSTGRES_PORT}
    POSTGRES_USER: ${AIRFLOW_POSTGRES_USER}
    POSTGRES_PASSWORD: ${AIRFLOW_POSTGRES_PASSWORD}
    POSTGRES_DB: ${AIRFLOW_POSTGRES_DB}
    LOG_LEVEL: ${LOG_LEVEL}
  volumes:
    # Airflow 관련 디렉토리
    - ./services/airflow/dags:/opt/airflow/dags
    - ./services/airflow/logs:/opt/airflow/logs
    - ./services/airflow/plugins:/opt/airflow/plugins
    - ./services/airflow/vector_store:/opt/airflow/vector_store
  depends_on: &airflow-common-depends-on
    postgres:
      condition: service_healthy

services:
  postgres:
    image: postgres:13
    environment:
      # API DB (기본 DB)
      POSTGRES_USER: ${API_POSTGRES_USER}
      POSTGRES_PASSWORD: ${API_POSTGRES_PASSWORD}
      POSTGRES_DB: ${API_POSTGRES_DB}
      # 다중 DB 설정
      POSTGRES_MULTIPLE_DATABASES: ${API_POSTGRES_DB},${AIRFLOW_POSTGRES_DB},${TEST_API_POSTGRES_DB},${TEST_AIRFLOW_POSTGRES_DB}
      # Airflow DB 사용자 정보
      AIRFLOW_POSTGRES_USER: ${AIRFLOW_POSTGRES_USER}
      AIRFLOW_POSTGRES_PASSWORD: ${AIRFLOW_POSTGRES_PASSWORD}
      AIRFLOW_POSTGRES_DB: ${AIRFLOW_POSTGRES_DB}
      # 테스트 DB 사용자 정보
      TEST_POSTGRES_USER: ${TEST_POSTGRES_USER}
      TEST_POSTGRES_PASSWORD: ${TEST_POSTGRES_PASSWORD}
      TEST_API_POSTGRES_DB: ${TEST_API_POSTGRES_DB}
      TEST_AIRFLOW_POSTGRES_DB: ${TEST_AIRFLOW_POSTGRES_DB}
    ports:
      - "${POSTGRES_PORT}:5432"
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
      - ./scripts/postgres:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${API_POSTGRES_USER}"]
      interval: 5s
      retries: 5
    restart: always

  redis:
    image: redis:latest
    ports:
      - "${REDIS_PORT}:6379"
    environment:
      - REDIS_PASSWORD=${REDIS_PASSWORD}
    volumes:
      - redis-data:/data
    restart: always

  api:
    build:
      context: .
      dockerfile: services/backend/Dockerfile
    ports:
      - "${API_PORT}:8000"
    environment:
      - API_HOST=${API_HOST}
      - DART_API_KEY=${DART_API_KEY}
      - VECTOR_DB_PATH=${API_VECTOR_DB_PATH}
      - POSTGRES_HOST=${POSTGRES_HOST}
      - POSTGRES_USER=${API_POSTGRES_USER}
      - POSTGRES_PASSWORD=${API_POSTGRES_PASSWORD}
      - POSTGRES_DB=${API_POSTGRES_DB}
      - REDIS_HOST=${REDIS_HOST}
      - REDIS_PORT=${REDIS_PORT}
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - LOG_LEVEL=${LOG_LEVEL}
    volumes:
      - ./services/backend:/app
      - ./data/vector_store:/data/vector_store
    depends_on:
      - postgres
      - redis

  frontend:
    build:
      context: .
      dockerfile: services/frontend/Dockerfile
    ports:
      - "${VITE_PORT}:${VITE_PORT}"
    volumes:
      - ./services/frontend:/app
      - /app/node_modules
    environment:
      - VITE_API_URL=${VITE_API_URL}
      - VITE_PORT=${VITE_PORT}
    depends_on:
      - api

  airflow-webserver:
    <<: *airflow-common
    command: webserver
    ports:
      - "${AIRFLOW_PORT}:8080"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    healthcheck:
      test: ["CMD-SHELL", 'airflow jobs check --job-type SchedulerJob --hostname "$${HOSTNAME}"']
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always

  airflow-init:
    <<: *airflow-common
    user: "${AIRFLOW_UID}:${AIRFLOW_GID}"
    entrypoint: /bin/bash
    command:
      - -c
      - |
        airflow db migrate &&
        airflow users create \
          --username ${AIRFLOW_ADMIN_USERNAME} \
          --firstname ${AIRFLOW_ADMIN_FIRSTNAME} \
          --lastname ${AIRFLOW_ADMIN_LASTNAME} \
          --role ${AIRFLOW_ADMIN_ROLE} \
          --email ${AIRFLOW_ADMIN_EMAIL} \
          --password ${AIRFLOW_ADMIN_PASSWORD}
    environment:
      <<: *airflow-common-env
    depends_on:
      postgres:
        condition: service_healthy

  grafana:
    image: grafana/grafana:latest
    ports:
      - "${GRAFANA_PORT}:3000"
    volumes:
      - grafana-storage:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
    depends_on:
      - postgres

volumes:
  postgres-db-volume:
  redis-data:
  grafana-storage: 